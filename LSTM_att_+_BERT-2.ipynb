{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y0fOWhqwW-AT"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install torch\n",
        "# !pip install nltk\n",
        "# !pip install tqdm\n",
        "# !pip install seaborn\n",
        "# !pip install numpy\n",
        "# !pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "83e409fa-cd09-4bda-e00d-ab5619dc96aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "7a322754-b3b5-40b1-f895-816154ed115f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-19 17:08:16--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M  96.4MB/s    in 0.3s    \n",
            "\n",
            "2021-12-19 17:08:16 (96.4 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "57a2a3ef-0e50-4921-9474-d3f4049b86df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec 19 17:08 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "5764dae2-9472-4be5-af2c-a68a2f624da0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-93b484ae-0886-4848-b928-6fbcd609352c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93b484ae-0886-4848-b928-6fbcd609352c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93b484ae-0886-4848-b928-6fbcd609352c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93b484ae-0886-4848-b928-6fbcd609352c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "f4d0c8a4-e2c8-4141-92e7-c69d7b07d32b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVhCzM3LW-Al",
        "outputId": "7b3fab20-aa1c-4919-bb35-8e51ed6690ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-19 17:23:46--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  35.7MB/s    in 36s     \n",
            "\n",
            "2021-12-19 17:24:22 (35.0 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJcT1qPZW-An",
        "outputId": "751326c4-89c3-4f05-8988-b25eca1d036f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec 19 17:08 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyI2erCDW-Ar",
        "outputId": "84a061a8-aefa-4542-9070-189c5d076d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:02<00:00, 97127.45it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "iZBR-aYDW-Av",
        "outputId": "9369cdc6-0a7e-425b-eaeb-81898a0a1115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe369ed32d0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "OBzmPqXIW-Aw",
        "outputId": "bfa0f141-3328-499d-d7d7-abea6eee1f03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSer_0bW-Ay",
        "outputId": "b938d548-82d7-40ef-f2f0-2fe0131d6a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "szg6XD3EW-Az",
        "outputId": "7d3425bd-6a09-44e6-b8ad-2638f4c7ecff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "779024d7-40b1-484e-c3cf-07447f37fe12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:12<00:00, 27738.09it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJMzgpnW-A7",
        "outputId": "921c2e99-8735-47a5-8ec4-0fa59c55af1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE06fafiW-A8",
        "outputId": "92513568-c7d6-4308-c6aa-5b553f328c7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy0lKr2W-BC",
        "outputId": "e19123db-9c6a-4f54-c31e-5898b8499ab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 841 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFlWdgtW-BE",
        "outputId": "b9f68780-4724-4e25-d8b9-e671ad3f3bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUQmRgtW-BK",
        "outputId": "a63f4af8-97a5-411a-d109-03a3bf195af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 27.9 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpit-1tW-BR",
        "outputId": "2c452878-1352-4faa-91f7-34af101aa56f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHdBavTWW-BT",
        "outputId": "e76db130-7a0b-488b-d5ae-9095a39d57f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcxv55j7W-BV",
        "outputId": "3cc63612-d0bb-48a8-a9bf-3bfda93b0095"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "68b75988-2829-41ae-9d07-b4812cfbac6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVn6YKLW-Bd",
        "outputId": "4ec6f20d-13c7-427d-bfe8-c478dbeeba5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N4w6-iWW-Be",
        "outputId": "150fddcc-84c9-4ae7-fd44-88806a842bc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C3_phaW-Bf",
        "outputId": "7759aa54-0cc2-4db3-a69c-0953d1670fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV76BdN0W-Bj",
        "outputId": "72f3a716-7f86-4b9d-dbc8-271f10feaed4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "INB_dPAnW-Bk",
        "outputId": "1543419e-20f6-48e4-a17d-750d00083d38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fed30c49-c679-429e-908e-0b073829f8db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed30c49-c679-429e-908e-0b073829f8db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fed30c49-c679-429e-908e-0b073829f8db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fed30c49-c679-429e-908e-0b073829f8db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x9QhXYW-Bn",
        "outputId": "3633c4d6-faf2-46ec-b61b-9b973a7332f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'food': 4, 'law': 1, 'love': 2, 'relax': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "05d7178d-8020-4662-f253-3fe68d811011"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:03<00:00, 67890.07it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 72358.71it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "ad8510b1-c796-4677-b206-6c5f3562078e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  75,    4, 2039,  ...,    0,    0,    0],\n",
              "        [  24, 2572,  514,  ...,    0,    0,    0],\n",
              "        [  26,  152,  562,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [6036, 5242,  425,  ...,    0,    0,    0],\n",
              "        [  24,  615, 2568,  ...,    0,    0,    0],\n",
              "        [  19, 7607, 7427,  ...,    0,    0,    0]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "239eb265-033f-4600-a84a-890642ea6dcf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 2, 2, 4, 4, 0, 1, 0, 3, 2, 2, 0, 2, 4, 0, 2, 2, 0, 1, 3, 1, 1, 2,\n",
              "        2, 1, 1, 2, 1, 3, 0, 3, 3, 0, 4, 3, 1, 4, 3, 4, 4, 1, 0, 1, 1, 4, 1, 1,\n",
              "        4, 1, 0, 4, 0, 0, 0, 1, 4, 4, 3, 1, 1, 3, 3, 2])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        self.LSTM = torch.nn.LSTM(input_size=300, hidden_size=256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
        "        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "        # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      #примените эмбеддинги\n",
        "      x_emb = self.embedding_layer(x)\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "d530e629-3360-45ee-aaf7-4d0e77f6dd78"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (embedding_layer): Embedding(117619, 300)\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E66MWNgM0QKM"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErboeQbv0dnC",
        "outputId": "bc2a9441-07ae-46af-c765-e59286f05725"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rUTc0l60pV9",
        "outputId": "03eb2947-8687-437e-bbdd-ccf7590c1cea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:29<00:00, 1019.46it/s, train_loss=0.475]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.565, test - 0.467\n",
            "F1 test - 0.829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:36<00:00, 990.48it/s, train_loss=0.441]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.453, test - 0.443\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:33<00:00, 1003.50it/s, train_loss=0.419]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.427, test - 0.436\n",
            "F1 test - 0.843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:29<00:00, 1021.82it/s, train_loss=0.396]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.404, test - 0.433\n",
            "F1 test - 0.845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:28<00:00, 1023.98it/s, train_loss=0.372]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.381, test - 0.443\n",
            "F1 test - 0.845\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aPjTQcR0vm2"
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwR0yMtkNiw_"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQo9zwC4ljTD"
      },
      "source": [
        "### Улучшение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk4TvirI5pLp"
      },
      "source": [
        "Попробуем увеличить dropout, поменять relu на leaky relu (и возможно размер hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5BgHdtW2sO3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "class model_with_att_new(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        self.LSTM = torch.nn.LSTM(input_size=300, hidden_size=256, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.q_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.k_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=512, out_features=256, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_3gr = torch.nn.Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
        "        self.cnn_4gr = torch.nn.Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(256, 128, kernel_size=(5,), stride=(1,))\n",
        "        # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.linear_1 = torch.nn.Linear(in_features=384, out_features=256, bias=True)\n",
        "        self.relu = torch.nn.LeakyReLU(0.1)\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=5, bias=True)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      #примените эмбеддинги\n",
        "      x_emb = self.embedding_layer(x)\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIa106RGl1n9"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_with_att_new(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMltRdgimDai"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBKKl_hwmWyQ",
        "outputId": "845d778a-a6f1-4426-a35a-5475c5f657d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [05:48<00:00, 614.75it/s, train_loss=0.477]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.580, test - 0.482\n",
            "F1 test - 0.824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [05:53<00:00, 605.94it/s, train_loss=0.442]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.453, test - 0.458\n",
            "F1 test - 0.835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [05:51<00:00, 608.88it/s, train_loss=0.418]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.426, test - 0.437\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [05:54<00:00, 604.03it/s, train_loss=0.396]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.405, test - 0.433\n",
            "F1 test - 0.843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [05:52<00:00, 607.53it/s, train_loss=0.374]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.383, test - 0.442\n",
            "F1 test - 0.841\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-rkhrRACAAs"
      },
      "source": [
        "Стало немного хуже, но не особо сильно. Попробуем вернуть dropout как было и уменьшить hidden_size слой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqrYkXW7CdCd"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from math import sqrt\n",
        "\n",
        "class model_with_att_new2(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.embedding_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        self.LSTM = torch.nn.LSTM(input_size=300, hidden_size=10, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.q_proj = torch.nn.Linear(in_features=20, out_features=64, bias=True)\n",
        "        self.k_proj = torch.nn.Linear(in_features=20, out_features=64, bias=True)\n",
        "        self.v_proj = torch.nn.Linear(in_features=20, out_features=64, bias=True)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_3gr = torch.nn.Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
        "        self.cnn_4gr = torch.nn.Conv1d(64, 32, kernel_size=(4,), stride=(1,))\n",
        "        self.cnn_5gr = torch.nn.Conv1d(64, 32, kernel_size=(5,), stride=(1,))\n",
        "        # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.linear_1 = torch.nn.Linear(in_features=96, out_features=32, bias=True)\n",
        "        self.relu = torch.nn.LeakyReLU(0.1)\n",
        "        self.linear_2 = torch.nn.Linear(in_features=32, out_features=5, bias=True)\n",
        "\n",
        "        \n",
        "  def forward(self, x):\n",
        "      #примените эмбеддинги\n",
        "      x_emb = self.embedding_layer(x)\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(2, 1)) /  math.sqrt(x_q.size(-1))\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "      \n",
        "      x = self.linear_1(x_cat) # пару полносвязных слоев с релу для классификации\n",
        "      x = self.relu(x)    \n",
        "      x = self.linear_2(x)\n",
        "    \n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2luQlGunCk5Y"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]\n",
        "model = model_with_att_new2(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WACo46vRDzVa"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNeyX4PeD3VC",
        "outputId": "c5a3aa03-3735-4ac6-b21f-6fa6d339cc73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [03:33<00:00, 1003.15it/s, train_loss=0.538]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.657, test - 0.562\n",
            "F1 test - 0.792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [03:32<00:00, 1005.10it/s, train_loss=0.489]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.506, test - 0.509\n",
            "F1 test - 0.813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [03:33<00:00, 1002.89it/s, train_loss=0.467]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.475, test - 0.478\n",
            "F1 test - 0.824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [03:33<00:00, 1002.83it/s, train_loss=0.452]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.458, test - 0.464\n",
            "F1 test - 0.831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [03:33<00:00, 1003.88it/s, train_loss=0.443]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.447, test - 0.455\n",
            "F1 test - 0.835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 214001/214001 [03:33<00:00, 1002.65it/s, train_loss=0.435]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.438, test - 0.450\n",
            "F1 test - 0.837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 214001/214001 [03:33<00:00, 1003.43it/s, train_loss=0.43]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.432, test - 0.446\n",
            "F1 test - 0.839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 214001/214001 [03:33<00:00, 1002.65it/s, train_loss=0.424]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.425, test - 0.443\n",
            "F1 test - 0.839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|██████████| 214001/214001 [03:33<00:00, 1001.15it/s, train_loss=0.42]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.420, test - 0.441\n",
            "F1 test - 0.841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|██████████| 214001/214001 [03:33<00:00, 1000.14it/s, train_loss=0.414]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.416, test - 0.437\n",
            "F1 test - 0.844\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F6G8800NNnz"
      },
      "source": [
        "Результаты вышли почти такими же, как и были с самого начала (которые были неплохими!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5MQYrllNxLx"
      },
      "source": [
        "### Работа с Бертом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c6Jg-nCBNWfW"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "b6dae22702ef47baa16206717204b7d9",
            "8f760a9dbce74842b81634f92b0694a0",
            "68f0f3d977ed4b698fedef10d9894cda",
            "7fddb9cb8c524e09bbff2ae16ebcd1a0",
            "cfcab892ec664d75b0ecebc8e37a80b5",
            "2d1562400fac47ab88d9d32a5413f489",
            "8da3565c711c42ed9d321fec52448202",
            "29f7bb7a425b4bb5b95756ef02bd6295",
            "df0e6c20e7f740e480424585342c16a3",
            "6e0b6aaf686a49d89c642cfec0188213",
            "be6a186f9dc043e8afdc3ba76af31a54",
            "45d783c241c8476e9b4412adbc25e4f6",
            "5ae8a1e09ab14dae8f4beeb1bdbbd2b7",
            "986b88d9c5b74841add8c4c177f33ba2",
            "c3ed99d392e2486ea4454bb0ad5e65a9",
            "8854bcd9c8d040a88001844b71e30484",
            "0fb1b924fe9b4715afddb7b64df558f4",
            "cdac406072c34e1e80e84f1de8c4af90",
            "e71ed19e76464a7ab49cd897a7a0e986",
            "10690406494e4103a37bc60bf55ea18f",
            "fc9c6fbf78cf45be8404199972f8e258",
            "6d1a478d77f1419db0faab93d0eca994",
            "dd3df35d222846d3b14ca778b0cf7b60",
            "9cb455bc08c243188f573181a86ff091",
            "fcca9ef3f5d24bc8bb64ec3db30b69b5",
            "0226de51dfbd4bdea2c2620fd94290ed",
            "e7c533339c90408bbabb0e5291472f47",
            "1ed5825ce92e4a378e0823cdf2298ad8",
            "f470e8c14b9f490f8faac92911ce6c3d",
            "2e354147f5cf49929a0d6713bd3a928d",
            "fc4464c10eba47439f2a1b600fc79269",
            "453282374fb94ef4ac25165420d40f7f",
            "4750155098b0453390d2e81fe86b8210",
            "7374d26110424478a388cb3b58eee7bc",
            "93cb337860de4cae900dd4b3dc623c17",
            "839afd67119f44cf88a890c1801dac5a",
            "3bbe060bb0594a29baeb7929a68e6db5",
            "d5232f87ee4943dcacd660de50b5c4d5",
            "0fd2ab2ede1949db835efdcbbe279838",
            "40a6e7dede454ee4b957e8d4999f7c8a",
            "652bca31b6f34d3dbb7f89ce59e28f82",
            "2035aba5ca6e40caa6b98f98d34ffda2",
            "53e28520edbe4c6a95ce37e5fbf1bff7",
            "7365ada2d72f489eaf97f8d36c0b388d"
          ]
        },
        "id": "hz1bYchUN4N2",
        "outputId": "8be584c9-cbba-4416-e001-53933b9baace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6dae22702ef47baa16206717204b7d9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45d783c241c8476e9b4412adbc25e4f6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd3df35d222846d3b14ca778b0cf7b60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.64M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7374d26110424478a388cb3b58eee7bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "UsOHDI0iOC26"
      },
      "outputs": [],
      "source": [
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTAVpBgWOJDA",
        "outputId": "bdb4d4f9-43b5-4618-c8c0-aed9009c31ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzMbWiL6OcCy",
        "outputId": "c6134852-af07-44f3-dad5-d199fd0a742b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "237779"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "len(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku9rac19Okqr",
        "outputId": "6912169d-1c34-4532-a6aa-9b27492ac725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  97\n"
          ]
        }
      ],
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIyOxOo9QEaY",
        "outputId": "5296d1fc-80fa-4f06-c0db-06348f375c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 97 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# Let's set max_len to 97\n",
        "MAX_LEN = 97\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "R5IAltrpQLfL"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "W4n6t_rqQYfr"
      },
      "outputs": [],
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "yhsFXXdLQfkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b91da2-ef6a-404b-c15d-7e2843ab60a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_WvxNUmXQkyr"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a4bb34ac7fcb4ee5abc5c75ed957b287",
            "be6d0dd11c3f44a7aff88c50a19eac98",
            "12051583e03349a0b8dbe367132b1495",
            "334c314bdbbc44b496107bbe67d9b589",
            "9b4726f1628b4a3d82a725d376b9bed1",
            "99d43a9617a7458d9b9de2cdc26c8c24",
            "b6bafd2ebdb5476cbf6de78aa961736f",
            "b3f639c2c13d4cd59f70e043a4f2fb13",
            "52abb476ec9149ab9c88c570bb69fad4",
            "ce9e2dc34f99495ba1e8f063be1bdeea",
            "66ef7109872c48dbb0dd7a131008ac5b"
          ]
        },
        "id": "N7eqNmScQrow",
        "outputId": "ccdb9d9b-c5f1-4511-cd62-9b6e307a2dd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4bb34ac7fcb4ee5abc5c75ed957b287",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/641M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "KKcNjesWRIe7"
      },
      "outputs": [],
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjWQorssRVQw",
        "outputId": "fb52197a-8394-4a00-c53e-6250365e8a14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Ow4ZrfqnRhcv"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "SPxIRHZtR7a7"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8WoDDC-SZ9G"
      },
      "source": [
        "будем высчитывать f-score, а не accuracy как в оригинальной тетрадке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IZBAvBNpSAN9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, pred_flat, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "bnO5a8QjSkFn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "взяла 1 эпоху, тк в коллабе бертовская модель обучается 2 часа, а на гпу часто превышается лимит."
      ],
      "metadata": {
        "id": "NGxmv2WkJ6c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UH_g-btbSoKX",
        "outputId": "8879b229-9e44-42be-facf-90c5911a7bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  6,688.    Elapsed: 0:00:40.\n",
            "  Batch    80  of  6,688.    Elapsed: 0:01:20.\n",
            "  Batch   120  of  6,688.    Elapsed: 0:02:00.\n",
            "  Batch   160  of  6,688.    Elapsed: 0:02:39.\n",
            "  Batch   200  of  6,688.    Elapsed: 0:03:19.\n",
            "  Batch   240  of  6,688.    Elapsed: 0:03:58.\n",
            "  Batch   280  of  6,688.    Elapsed: 0:04:38.\n",
            "  Batch   320  of  6,688.    Elapsed: 0:05:17.\n",
            "  Batch   360  of  6,688.    Elapsed: 0:05:57.\n",
            "  Batch   400  of  6,688.    Elapsed: 0:06:36.\n",
            "  Batch   440  of  6,688.    Elapsed: 0:07:16.\n",
            "  Batch   480  of  6,688.    Elapsed: 0:07:55.\n",
            "  Batch   520  of  6,688.    Elapsed: 0:08:34.\n",
            "  Batch   560  of  6,688.    Elapsed: 0:09:14.\n",
            "  Batch   600  of  6,688.    Elapsed: 0:09:53.\n",
            "  Batch   640  of  6,688.    Elapsed: 0:10:33.\n",
            "  Batch   680  of  6,688.    Elapsed: 0:11:12.\n",
            "  Batch   720  of  6,688.    Elapsed: 0:11:51.\n",
            "  Batch   760  of  6,688.    Elapsed: 0:12:31.\n",
            "  Batch   800  of  6,688.    Elapsed: 0:13:10.\n",
            "  Batch   840  of  6,688.    Elapsed: 0:13:49.\n",
            "  Batch   880  of  6,688.    Elapsed: 0:14:29.\n",
            "  Batch   920  of  6,688.    Elapsed: 0:15:08.\n",
            "  Batch   960  of  6,688.    Elapsed: 0:15:48.\n",
            "  Batch 1,000  of  6,688.    Elapsed: 0:16:27.\n",
            "  Batch 1,040  of  6,688.    Elapsed: 0:17:06.\n",
            "  Batch 1,080  of  6,688.    Elapsed: 0:17:45.\n",
            "  Batch 1,120  of  6,688.    Elapsed: 0:18:25.\n",
            "  Batch 1,160  of  6,688.    Elapsed: 0:19:04.\n",
            "  Batch 1,200  of  6,688.    Elapsed: 0:19:43.\n",
            "  Batch 1,240  of  6,688.    Elapsed: 0:20:23.\n",
            "  Batch 1,280  of  6,688.    Elapsed: 0:21:02.\n",
            "  Batch 1,320  of  6,688.    Elapsed: 0:21:41.\n",
            "  Batch 1,360  of  6,688.    Elapsed: 0:22:20.\n",
            "  Batch 1,400  of  6,688.    Elapsed: 0:23:00.\n",
            "  Batch 1,440  of  6,688.    Elapsed: 0:23:39.\n",
            "  Batch 1,480  of  6,688.    Elapsed: 0:24:18.\n",
            "  Batch 1,520  of  6,688.    Elapsed: 0:24:57.\n",
            "  Batch 1,560  of  6,688.    Elapsed: 0:25:37.\n",
            "  Batch 1,600  of  6,688.    Elapsed: 0:26:16.\n",
            "  Batch 1,640  of  6,688.    Elapsed: 0:26:55.\n",
            "  Batch 1,680  of  6,688.    Elapsed: 0:27:35.\n",
            "  Batch 1,720  of  6,688.    Elapsed: 0:28:14.\n",
            "  Batch 1,760  of  6,688.    Elapsed: 0:28:54.\n",
            "  Batch 1,800  of  6,688.    Elapsed: 0:29:33.\n",
            "  Batch 1,840  of  6,688.    Elapsed: 0:30:12.\n",
            "  Batch 1,880  of  6,688.    Elapsed: 0:30:51.\n",
            "  Batch 1,920  of  6,688.    Elapsed: 0:31:30.\n",
            "  Batch 1,960  of  6,688.    Elapsed: 0:32:10.\n",
            "  Batch 2,000  of  6,688.    Elapsed: 0:32:49.\n",
            "  Batch 2,040  of  6,688.    Elapsed: 0:33:28.\n",
            "  Batch 2,080  of  6,688.    Elapsed: 0:34:08.\n",
            "  Batch 2,120  of  6,688.    Elapsed: 0:34:47.\n",
            "  Batch 2,160  of  6,688.    Elapsed: 0:35:26.\n",
            "  Batch 2,200  of  6,688.    Elapsed: 0:36:06.\n",
            "  Batch 2,240  of  6,688.    Elapsed: 0:36:45.\n",
            "  Batch 2,280  of  6,688.    Elapsed: 0:37:24.\n",
            "  Batch 2,320  of  6,688.    Elapsed: 0:38:04.\n",
            "  Batch 2,360  of  6,688.    Elapsed: 0:38:43.\n",
            "  Batch 2,400  of  6,688.    Elapsed: 0:39:22.\n",
            "  Batch 2,440  of  6,688.    Elapsed: 0:40:02.\n",
            "  Batch 2,480  of  6,688.    Elapsed: 0:40:41.\n",
            "  Batch 2,520  of  6,688.    Elapsed: 0:41:21.\n",
            "  Batch 2,560  of  6,688.    Elapsed: 0:42:00.\n",
            "  Batch 2,600  of  6,688.    Elapsed: 0:42:39.\n",
            "  Batch 2,640  of  6,688.    Elapsed: 0:43:19.\n",
            "  Batch 2,680  of  6,688.    Elapsed: 0:43:58.\n",
            "  Batch 2,720  of  6,688.    Elapsed: 0:44:38.\n",
            "  Batch 2,760  of  6,688.    Elapsed: 0:45:17.\n",
            "  Batch 2,800  of  6,688.    Elapsed: 0:45:56.\n",
            "  Batch 2,840  of  6,688.    Elapsed: 0:46:35.\n",
            "  Batch 2,880  of  6,688.    Elapsed: 0:47:15.\n",
            "  Batch 2,920  of  6,688.    Elapsed: 0:47:54.\n",
            "  Batch 2,960  of  6,688.    Elapsed: 0:48:33.\n",
            "  Batch 3,000  of  6,688.    Elapsed: 0:49:13.\n",
            "  Batch 3,040  of  6,688.    Elapsed: 0:49:52.\n",
            "  Batch 3,080  of  6,688.    Elapsed: 0:50:32.\n",
            "  Batch 3,120  of  6,688.    Elapsed: 0:51:11.\n",
            "  Batch 3,160  of  6,688.    Elapsed: 0:51:50.\n",
            "  Batch 3,200  of  6,688.    Elapsed: 0:52:30.\n",
            "  Batch 3,240  of  6,688.    Elapsed: 0:53:09.\n",
            "  Batch 3,280  of  6,688.    Elapsed: 0:53:49.\n",
            "  Batch 3,320  of  6,688.    Elapsed: 0:54:28.\n",
            "  Batch 3,360  of  6,688.    Elapsed: 0:55:08.\n",
            "  Batch 3,400  of  6,688.    Elapsed: 0:55:47.\n",
            "  Batch 3,440  of  6,688.    Elapsed: 0:56:26.\n",
            "  Batch 3,480  of  6,688.    Elapsed: 0:57:06.\n",
            "  Batch 3,520  of  6,688.    Elapsed: 0:57:45.\n",
            "  Batch 3,560  of  6,688.    Elapsed: 0:58:24.\n",
            "  Batch 3,600  of  6,688.    Elapsed: 0:59:04.\n",
            "  Batch 3,640  of  6,688.    Elapsed: 0:59:43.\n",
            "  Batch 3,680  of  6,688.    Elapsed: 1:00:23.\n",
            "  Batch 3,720  of  6,688.    Elapsed: 1:01:02.\n",
            "  Batch 3,760  of  6,688.    Elapsed: 1:01:41.\n",
            "  Batch 3,800  of  6,688.    Elapsed: 1:02:21.\n",
            "  Batch 3,840  of  6,688.    Elapsed: 1:03:00.\n",
            "  Batch 3,880  of  6,688.    Elapsed: 1:03:39.\n",
            "  Batch 3,920  of  6,688.    Elapsed: 1:04:19.\n",
            "  Batch 3,960  of  6,688.    Elapsed: 1:04:58.\n",
            "  Batch 4,000  of  6,688.    Elapsed: 1:05:37.\n",
            "  Batch 4,040  of  6,688.    Elapsed: 1:06:17.\n",
            "  Batch 4,080  of  6,688.    Elapsed: 1:06:56.\n",
            "  Batch 4,120  of  6,688.    Elapsed: 1:07:35.\n",
            "  Batch 4,160  of  6,688.    Elapsed: 1:08:15.\n",
            "  Batch 4,200  of  6,688.    Elapsed: 1:08:54.\n",
            "  Batch 4,240  of  6,688.    Elapsed: 1:09:33.\n",
            "  Batch 4,280  of  6,688.    Elapsed: 1:10:13.\n",
            "  Batch 4,320  of  6,688.    Elapsed: 1:10:52.\n",
            "  Batch 4,360  of  6,688.    Elapsed: 1:11:31.\n",
            "  Batch 4,400  of  6,688.    Elapsed: 1:12:11.\n",
            "  Batch 4,440  of  6,688.    Elapsed: 1:12:50.\n",
            "  Batch 4,480  of  6,688.    Elapsed: 1:13:30.\n",
            "  Batch 4,520  of  6,688.    Elapsed: 1:14:09.\n",
            "  Batch 4,560  of  6,688.    Elapsed: 1:14:48.\n",
            "  Batch 4,600  of  6,688.    Elapsed: 1:15:28.\n",
            "  Batch 4,640  of  6,688.    Elapsed: 1:16:07.\n",
            "  Batch 4,680  of  6,688.    Elapsed: 1:16:46.\n",
            "  Batch 4,720  of  6,688.    Elapsed: 1:17:26.\n",
            "  Batch 4,760  of  6,688.    Elapsed: 1:18:05.\n",
            "  Batch 4,800  of  6,688.    Elapsed: 1:18:45.\n",
            "  Batch 4,840  of  6,688.    Elapsed: 1:19:24.\n",
            "  Batch 4,880  of  6,688.    Elapsed: 1:20:03.\n",
            "  Batch 4,920  of  6,688.    Elapsed: 1:20:43.\n",
            "  Batch 4,960  of  6,688.    Elapsed: 1:21:22.\n",
            "  Batch 5,000  of  6,688.    Elapsed: 1:22:01.\n",
            "  Batch 5,040  of  6,688.    Elapsed: 1:22:41.\n",
            "  Batch 5,080  of  6,688.    Elapsed: 1:23:20.\n",
            "  Batch 5,120  of  6,688.    Elapsed: 1:23:59.\n",
            "  Batch 5,160  of  6,688.    Elapsed: 1:24:39.\n",
            "  Batch 5,200  of  6,688.    Elapsed: 1:25:18.\n",
            "  Batch 5,240  of  6,688.    Elapsed: 1:25:58.\n",
            "  Batch 5,280  of  6,688.    Elapsed: 1:26:37.\n",
            "  Batch 5,320  of  6,688.    Elapsed: 1:27:17.\n",
            "  Batch 5,360  of  6,688.    Elapsed: 1:27:56.\n",
            "  Batch 5,400  of  6,688.    Elapsed: 1:28:35.\n",
            "  Batch 5,440  of  6,688.    Elapsed: 1:29:15.\n",
            "  Batch 5,480  of  6,688.    Elapsed: 1:29:54.\n",
            "  Batch 5,520  of  6,688.    Elapsed: 1:30:34.\n",
            "  Batch 5,560  of  6,688.    Elapsed: 1:31:13.\n",
            "  Batch 5,600  of  6,688.    Elapsed: 1:31:53.\n",
            "  Batch 5,640  of  6,688.    Elapsed: 1:32:32.\n",
            "  Batch 5,680  of  6,688.    Elapsed: 1:33:11.\n",
            "  Batch 5,720  of  6,688.    Elapsed: 1:33:51.\n",
            "  Batch 5,760  of  6,688.    Elapsed: 1:34:30.\n",
            "  Batch 5,800  of  6,688.    Elapsed: 1:35:10.\n",
            "  Batch 5,840  of  6,688.    Elapsed: 1:35:49.\n",
            "  Batch 5,880  of  6,688.    Elapsed: 1:36:28.\n",
            "  Batch 5,920  of  6,688.    Elapsed: 1:37:08.\n",
            "  Batch 5,960  of  6,688.    Elapsed: 1:37:47.\n",
            "  Batch 6,000  of  6,688.    Elapsed: 1:38:27.\n",
            "  Batch 6,040  of  6,688.    Elapsed: 1:39:06.\n",
            "  Batch 6,080  of  6,688.    Elapsed: 1:39:46.\n",
            "  Batch 6,120  of  6,688.    Elapsed: 1:40:25.\n",
            "  Batch 6,160  of  6,688.    Elapsed: 1:41:04.\n",
            "  Batch 6,200  of  6,688.    Elapsed: 1:41:44.\n",
            "  Batch 6,240  of  6,688.    Elapsed: 1:42:23.\n",
            "  Batch 6,280  of  6,688.    Elapsed: 1:43:03.\n",
            "  Batch 6,320  of  6,688.    Elapsed: 1:43:42.\n",
            "  Batch 6,360  of  6,688.    Elapsed: 1:44:22.\n",
            "  Batch 6,400  of  6,688.    Elapsed: 1:45:01.\n",
            "  Batch 6,440  of  6,688.    Elapsed: 1:45:40.\n",
            "  Batch 6,480  of  6,688.    Elapsed: 1:46:20.\n",
            "  Batch 6,520  of  6,688.    Elapsed: 1:46:59.\n",
            "  Batch 6,560  of  6,688.    Elapsed: 1:47:38.\n",
            "  Batch 6,600  of  6,688.    Elapsed: 1:48:18.\n",
            "  Batch 6,640  of  6,688.    Elapsed: 1:48:57.\n",
            "  Batch 6,680  of  6,688.    Elapsed: 1:49:36.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 1:49:44\n",
            "\n",
            "Running Validation...\n",
            "  F1-score: 0.85\n",
            "  Validation took: 0:04:18\n",
            "\n",
            "======== Epoch 2 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of  6,688.    Elapsed: 0:00:39.\n",
            "  Batch    80  of  6,688.    Elapsed: 0:01:19.\n",
            "  Batch   120  of  6,688.    Elapsed: 0:01:58.\n",
            "  Batch   160  of  6,688.    Elapsed: 0:02:38.\n",
            "  Batch   200  of  6,688.    Elapsed: 0:03:17.\n",
            "  Batch   240  of  6,688.    Elapsed: 0:03:57.\n",
            "  Batch   280  of  6,688.    Elapsed: 0:04:36.\n",
            "  Batch   320  of  6,688.    Elapsed: 0:05:15.\n",
            "  Batch   360  of  6,688.    Elapsed: 0:05:55.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-ff6b5011cb1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, 3):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  F1-score: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "результат даже чуть выше чем в предыдущей модели. пришлось остановить обучение, тк оно очень долгое и гпу исчерпывается в колабе, но если еще дообучить, то можно результаты и выше получить."
      ],
      "metadata": {
        "id": "zVAjHV_JlnuT"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_att_+_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6dae22702ef47baa16206717204b7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8f760a9dbce74842b81634f92b0694a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68f0f3d977ed4b698fedef10d9894cda",
              "IPY_MODEL_7fddb9cb8c524e09bbff2ae16ebcd1a0",
              "IPY_MODEL_cfcab892ec664d75b0ecebc8e37a80b5"
            ]
          }
        },
        "8f760a9dbce74842b81634f92b0694a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68f0f3d977ed4b698fedef10d9894cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2d1562400fac47ab88d9d32a5413f489",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8da3565c711c42ed9d321fec52448202"
          }
        },
        "7fddb9cb8c524e09bbff2ae16ebcd1a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29f7bb7a425b4bb5b95756ef02bd6295",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 871891,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 871891,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df0e6c20e7f740e480424585342c16a3"
          }
        },
        "cfcab892ec664d75b0ecebc8e37a80b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e0b6aaf686a49d89c642cfec0188213",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 851k/851k [00:00&lt;00:00, 989kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be6a186f9dc043e8afdc3ba76af31a54"
          }
        },
        "2d1562400fac47ab88d9d32a5413f489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8da3565c711c42ed9d321fec52448202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "29f7bb7a425b4bb5b95756ef02bd6295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df0e6c20e7f740e480424585342c16a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e0b6aaf686a49d89c642cfec0188213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be6a186f9dc043e8afdc3ba76af31a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45d783c241c8476e9b4412adbc25e4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ae8a1e09ab14dae8f4beeb1bdbbd2b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_986b88d9c5b74841add8c4c177f33ba2",
              "IPY_MODEL_c3ed99d392e2486ea4454bb0ad5e65a9",
              "IPY_MODEL_8854bcd9c8d040a88001844b71e30484"
            ]
          }
        },
        "5ae8a1e09ab14dae8f4beeb1bdbbd2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "986b88d9c5b74841add8c4c177f33ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fb1b924fe9b4715afddb7b64df558f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdac406072c34e1e80e84f1de8c4af90"
          }
        },
        "c3ed99d392e2486ea4454bb0ad5e65a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e71ed19e76464a7ab49cd897a7a0e986",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10690406494e4103a37bc60bf55ea18f"
          }
        },
        "8854bcd9c8d040a88001844b71e30484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc9c6fbf78cf45be8404199972f8e258",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 304B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d1a478d77f1419db0faab93d0eca994"
          }
        },
        "0fb1b924fe9b4715afddb7b64df558f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdac406072c34e1e80e84f1de8c4af90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e71ed19e76464a7ab49cd897a7a0e986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10690406494e4103a37bc60bf55ea18f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc9c6fbf78cf45be8404199972f8e258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d1a478d77f1419db0faab93d0eca994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd3df35d222846d3b14ca778b0cf7b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9cb455bc08c243188f573181a86ff091",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fcca9ef3f5d24bc8bb64ec3db30b69b5",
              "IPY_MODEL_0226de51dfbd4bdea2c2620fd94290ed",
              "IPY_MODEL_e7c533339c90408bbabb0e5291472f47"
            ]
          }
        },
        "9cb455bc08c243188f573181a86ff091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fcca9ef3f5d24bc8bb64ec3db30b69b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ed5825ce92e4a378e0823cdf2298ad8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f470e8c14b9f490f8faac92911ce6c3d"
          }
        },
        "0226de51dfbd4bdea2c2620fd94290ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e354147f5cf49929a0d6713bd3a928d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1715180,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1715180,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc4464c10eba47439f2a1b600fc79269"
          }
        },
        "e7c533339c90408bbabb0e5291472f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_453282374fb94ef4ac25165420d40f7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.64M/1.64M [00:00&lt;00:00, 3.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4750155098b0453390d2e81fe86b8210"
          }
        },
        "1ed5825ce92e4a378e0823cdf2298ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f470e8c14b9f490f8faac92911ce6c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e354147f5cf49929a0d6713bd3a928d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc4464c10eba47439f2a1b600fc79269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "453282374fb94ef4ac25165420d40f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4750155098b0453390d2e81fe86b8210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7374d26110424478a388cb3b58eee7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93cb337860de4cae900dd4b3dc623c17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_839afd67119f44cf88a890c1801dac5a",
              "IPY_MODEL_3bbe060bb0594a29baeb7929a68e6db5",
              "IPY_MODEL_d5232f87ee4943dcacd660de50b5c4d5"
            ]
          }
        },
        "93cb337860de4cae900dd4b3dc623c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "839afd67119f44cf88a890c1801dac5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fd2ab2ede1949db835efdcbbe279838",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40a6e7dede454ee4b957e8d4999f7c8a"
          }
        },
        "3bbe060bb0594a29baeb7929a68e6db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_652bca31b6f34d3dbb7f89ce59e28f82",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2035aba5ca6e40caa6b98f98d34ffda2"
          }
        },
        "d5232f87ee4943dcacd660de50b5c4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53e28520edbe4c6a95ce37e5fbf1bff7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 6.96kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7365ada2d72f489eaf97f8d36c0b388d"
          }
        },
        "0fd2ab2ede1949db835efdcbbe279838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40a6e7dede454ee4b957e8d4999f7c8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "652bca31b6f34d3dbb7f89ce59e28f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2035aba5ca6e40caa6b98f98d34ffda2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53e28520edbe4c6a95ce37e5fbf1bff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7365ada2d72f489eaf97f8d36c0b388d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4bb34ac7fcb4ee5abc5c75ed957b287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be6d0dd11c3f44a7aff88c50a19eac98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12051583e03349a0b8dbe367132b1495",
              "IPY_MODEL_334c314bdbbc44b496107bbe67d9b589",
              "IPY_MODEL_9b4726f1628b4a3d82a725d376b9bed1"
            ]
          }
        },
        "be6d0dd11c3f44a7aff88c50a19eac98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12051583e03349a0b8dbe367132b1495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99d43a9617a7458d9b9de2cdc26c8c24",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6bafd2ebdb5476cbf6de78aa961736f"
          }
        },
        "334c314bdbbc44b496107bbe67d9b589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3f639c2c13d4cd59f70e043a4f2fb13",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 672271273,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 672271273,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52abb476ec9149ab9c88c570bb69fad4"
          }
        },
        "9b4726f1628b4a3d82a725d376b9bed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ce9e2dc34f99495ba1e8f063be1bdeea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 641M/641M [00:59&lt;00:00, 6.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66ef7109872c48dbb0dd7a131008ac5b"
          }
        },
        "99d43a9617a7458d9b9de2cdc26c8c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6bafd2ebdb5476cbf6de78aa961736f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3f639c2c13d4cd59f70e043a4f2fb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52abb476ec9149ab9c88c570bb69fad4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce9e2dc34f99495ba1e8f063be1bdeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66ef7109872c48dbb0dd7a131008ac5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}